import os
from flask import Flask, render_template, request, redirect, url_for, send_file, session, flash
from supabase import create_client, Client

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
    print(f"[ENV] .env íŒŒì¼ ë¡œë“œ ì™„ë£Œ. KAKAO_REST_API_KEY: {'ì„¤ì •ë¨' if os.environ.get('KAKAO_REST_API_KEY') else 'ì—†ìŒ'}")
except ImportError:
    print("[ENV] python-dotenv íŒ¨í‚¤ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ê°€ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")
except Exception as e:
    print(f"[ENV] .env íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
import pandas as pd
import numpy as np
from werkzeug.utils import secure_filename
from datetime import datetime
import io
import requests
from typing import Optional
import hashlib
import time
import re

# --- Custom Modules ---
from config import get_config, Config
from data_processing import (
    normalize_columns,
    process_uploaded_csv,
    get_stats,
    clean_for_json,
    match_with_supabase
)
from map_utils import get_latlon_from_address, clear_cache

# --- Application Factory ---
def create_app(config_name='default'):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ íŒ©í† ë¦¬ í•¨ìˆ˜"""
    app = Flask(__name__)
    
    # ì„¤ì • ë¡œë“œ
    config = get_config(config_name)
    app.config.from_object(config)
    
    # ì„¤ì • ê²€ì¦
    try:
        config.validate_config()
    except ValueError as e:
        print(f"[ERROR] ì„¤ì • ê²€ì¦ ì‹¤íŒ¨: {e}")
        raise
    
    # ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(app.config['UPLOAD_FOLDER'], exist_ok=True)
    
    # Supabase í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    supabase = create_client(
        app.config['SUPABASE_URL'],
        app.config['SUPABASE_KEY']
    )
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì»¨í…ìŠ¤íŠ¸ì— í´ë¼ì´ì–¸íŠ¸ ì €ì¥
    app.supabase = supabase
    
    # íŒŒì¼ í¬ê¸° ì´ˆê³¼ ì˜¤ë¥˜ í•¸ë“¤ëŸ¬
    @app.errorhandler(413)
    def request_entity_too_large(error):
        flash('íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 50MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))
    
    return app

# --- ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„± ---
app = create_app(os.environ.get('FLASK_ENV', 'default'))
supabase = app.supabase

# --- ì‹ ê·œ ì•„íŒŒíŠ¸ DB ì¶”ê°€ í•¨ìˆ˜ ---
def insert_new_apartments_to_supabase(df, supabase):
    # ìœ„ë„/ê²½ë„ ì—†ëŠ”(ë§¤ì¹­ ì•ˆ ëœ) ë‹¨ì§€ë§Œ ì¶”ì¶œ
    new_apts = df[df['ìœ„ë„'].isna() | df['ê²½ë„'].isna()].copy()
    # ì‹œêµ°êµ¬+ë²ˆì§€ ì¡°í•© ì»¬ëŸ¼ ìƒì„±
    new_apts['lnno_adres'] = new_apts.apply(lambda row: f"{row.get('ì‹œêµ°êµ¬', '')} {row.get('ë²ˆì§€', '')}", axis=1)
    # ë‹¨ì§€ëª…, ë„ë¡œëª…, lnno_adres, ê±´ì¶•ë…„ë„ ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
    deduped = new_apts.drop_duplicates(subset=['ë‹¨ì§€ëª…', 'ë„ë¡œëª…', 'lnno_adres', 'ê±´ì¶•ë…„ë„'])
    for _, row in deduped.iterrows():
        data = {
            'apt_nm': row.get('ë‹¨ì§€ëª…', ''),
            'rdnmadr': row.get('ë„ë¡œëª…', ''),
            'use_aprv_yr': row.get('ê±´ì¶•ë…„ë„', ''),
            'lnno_adres': row.get('lnno_adres', ''),
        }
        supabase.table('apt_master_info').insert(data).execute()

# ------------------- Routes -------------------

@app.route('/')
def index():
    # í…œí”Œë¦¿ ë Œë”ë§ ì „ì— í”Œë˜ì‹œ ë©”ì‹œì§€ í™•ì¸
    print(f"[DEBUG] Flash messages: {session.get('_flashes', [])}")
    return render_template('index.html')

@app.route('/analysis')
def analysis():
    """ë¶„ì„ ê²°ê³¼ í˜ì´ì§€ - GET ìš”ì²­ìœ¼ë¡œë§Œ ì ‘ê·¼ ê°€ëŠ¥"""
    if 'datafile' not in session:
        return redirect(url_for('index'))
    
    temp_filename = session['datafile']
    temp_path = os.path.join(app.config['UPLOAD_FOLDER'], os.path.basename(temp_filename))
    
    if not os.path.exists(temp_path):
        return redirect(url_for('index'))
    
    try:
        df = pd.read_csv(temp_path, encoding='utf-8-sig')
        columns = df.columns.tolist()
        stats = get_stats(df)
        
        return render_template('analysis.html', 
                             stats=stats, 
                             columns=columns, 
                             analyzed_file=temp_filename)
    except Exception as e:
        print(f"[Analysis Error] {e}")
        return redirect(url_for('index'))

def get_file_hash(file_path):
    with open(file_path, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        print(f"[UPLOAD] ğŸš€ === ë°ì´í„° ë¶„ì„ ì‹œì‘ ===")
        print(f"[UPLOAD] ğŸ“ ìš”ì²­ ì •ë³´: {request.method} - {request.content_type}")
        print(f"[UPLOAD] ğŸ“ íŒŒì¼ í‚¤: {list(request.files.keys())}")
        print(f"[UPLOAD] ğŸ”„ ë‹¨ê³„ 1/6: íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘...")
        
        # 'file' í‚¤ê°€ ìˆëŠ”ì§€ í™•ì¸
        if 'file' not in request.files:
            print("[UPLOAD] 'file' key not in request.files")
            flash('íŒŒì¼ ì—…ë¡œë“œ ìš”ì²­ì— íŒŒì¼ì´ í¬í•¨ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.', 'error')
            return redirect(url_for('index'))
        
        file = request.files['file']
        print(f"[UPLOAD] File object: {file}")
        print(f"[UPLOAD] File filename: {getattr(file, 'filename', 'NO_FILENAME')}")
        
        if not file or not file.filename:
            print("[UPLOAD] No file or no filename")
            flash('CSV íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.', 'error')
            return redirect(url_for('index'))
            
        if not file.filename.endswith('.csv'):
            print(f"[UPLOAD] Invalid file extension: {file.filename}")
            flash('CSV íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤. (.csv í™•ì¥ì í•„ìš”)', 'error')
            return redirect(url_for('index'))
        
        print(f"[UPLOAD] File validation passed: {file.filename}")
        
        # íŒŒì¼ í¬ê¸° ê²€ì¦
        if file.content_length and file.content_length > app.config.get('MAX_CONTENT_LENGTH', 50*1024*1024):
            flash(f'íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. ìµœëŒ€ 50MBê¹Œì§€ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤.', 'error')
            return redirect(url_for('index'))
        
        # ì „ìš©ë©´ì  êµ¬ê°„ ì„ íƒê°’ ë°›ê¸°
        area_range = request.form.get('area_range', 'all')
        session['area_range'] = area_range
        
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)
        print(f"[UPLOAD] ğŸ’¾ íŒŒì¼ ì €ì¥: {file_path}")
        print(f"[UPLOAD] ğŸ“ íŒŒì¼ í¬ê¸°: {os.path.getsize(file_path):,} bytes")
        print(f"[UPLOAD] âœ… ë‹¨ê³„ 1/6: íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

        # íŒŒì¼ í•´ì‹œë¡œ ë¶„ì„ ê²°ê³¼ ìºì‹±
        file_hash = get_file_hash(file_path)
        analyzed_path = os.path.join(app.config['UPLOAD_FOLDER'], f'{file_hash}_ë¶„ì„ì™„ë£Œ.csv')
        
        if os.path.exists(analyzed_path):
            print(f"[UPLOAD] ğŸ¯ ìºì‹œ íŒŒì¼ ë°œê²¬: {analyzed_path}")
            print(f"[UPLOAD] ğŸ“Š ìºì‹œ íŒŒì¼ í¬ê¸°: {os.path.getsize(analyzed_path):,} bytes")
            print(f"[UPLOAD] âš¡ ìºì‹œ íŒŒì¼ ì‚¬ìš©ìœ¼ë¡œ ë¹ ë¥¸ ì²˜ë¦¬")
            df = pd.read_csv(analyzed_path, encoding='utf-8-sig')
            columns = df.columns.tolist()
            temp_path = analyzed_path
        else:
            print("[UPLOAD] ğŸ”„ ë‹¨ê³„ 2/6: ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘...")
            temp_path, columns = process_uploaded_csv(file_path)
            print(f"[UPLOAD] âœ… ë‹¨ê³„ 2/6: ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ - ì²˜ë¦¬ëœ íŒŒì¼: {temp_path}")
            df = pd.read_csv(temp_path, encoding='utf-8-sig')
            print(f"[UPLOAD] ğŸ“Š ë°ì´í„° ë¡œë“œ ì™„ë£Œ - í–‰ ìˆ˜: {len(df)}, ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}")
            print(f"[UPLOAD] ğŸ“‹ ì»¬ëŸ¼ ëª©ë¡: {df.columns.tolist()}")
            
            print("[UPLOAD] ğŸ”„ ë‹¨ê³„ 3/6: Supabase DB ì¢Œí‘œ ì¡°íšŒ ì‹œì‘...")
            df = match_with_supabase(df, supabase)  # ì¬í™œì„±í™”
            print("[UPLOAD] âœ… ë‹¨ê³„ 3/6: Supabase DB ì¢Œí‘œ ì¡°íšŒ ì™„ë£Œ")
            
            # ì‹ ê·œ ì•„íŒŒíŠ¸ ì •ë³´ DB ì €ì¥
            print("[UPLOAD] ğŸ”„ ë‹¨ê³„ 4/6: ì‹ ê·œ ì•„íŒŒíŠ¸ ì •ë³´ DB ì €ì¥ ì‹œì‘...")
            try:
                insert_new_apartments_to_supabase(df, supabase)
                print("[UPLOAD] âœ… ë‹¨ê³„ 4/6: ì‹ ê·œ ì•„íŒŒíŠ¸ ì •ë³´ DB ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                print(f"[UPLOAD] âŒ ë‹¨ê³„ 4/6: ì‹ ê·œ ì•„íŒŒíŠ¸ ì •ë³´ DB ì €ì¥ ì‹¤íŒ¨: {e}")
            
            # ì¢Œí‘œ ë³€í™˜ ë° DB ì €ì¥ ì™„ë£Œ
            print("[UPLOAD] ğŸ”„ ë‹¨ê³„ 5/6: ë°ì´í„° ë¶„ì„ ì‹œì‘...")
            coord_count = df[['ìœ„ë„', 'ê²½ë„']].dropna().shape[0]
            print(f"[UPLOAD] ğŸ“ ì¢Œí‘œ ë³´ìœ  ë°ì´í„°: {coord_count}ê±´ / ì „ì²´ {len(df)}ê±´")
            print("[UPLOAD] âœ… ë‹¨ê³„ 5/6: ë°ì´í„° ë¶„ì„ ì™„ë£Œ")
            
            # ë¶„ì„ ê²°ê³¼ë¥¼ ìºì‹œ íŒŒì¼ë¡œ ì €ì¥
            print("[UPLOAD] ğŸ”„ ë‹¨ê³„ 6/6: ê²°ê³¼ íŒŒì¼ ìƒì„± ì‹œì‘...")
            df.to_csv(analyzed_path, index=False, encoding='utf-8-sig')
            temp_path = analyzed_path
            print(f"[UPLOAD] ğŸ’¾ ê²°ê³¼ íŒŒì¼ ì €ì¥: {analyzed_path}")
            print("[UPLOAD] âœ… ë‹¨ê³„ 6/6: ê²°ê³¼ íŒŒì¼ ìƒì„± ì™„ë£Œ")
            
        session['datafile'] = os.path.basename(temp_path)
        print(f"[UPLOAD] ğŸ‰ === ë°ì´í„° ë¶„ì„ ì™„ë£Œ === ì´ {len(df) if 'df' in locals() else 0}ê±´ ì²˜ë¦¬")
        print(f"[UPLOAD] Processed file saved to session: {session['datafile']}")
        stats = get_stats(df)
        print("[UPLOAD] Stats generated. Rendering analysis.html...")
        return render_template('analysis.html', stats=stats, columns=columns, analyzed_file=filename)
    except FileNotFoundError as e:
        print(f"[Upload Error - File Not Found] {e}")
        flash('íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))
    except pd.errors.EmptyDataError as e:
        print(f"[Upload Error - Empty Data] {e}")
        flash('ë¹ˆ íŒŒì¼ì´ê±°ë‚˜ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))
    except pd.errors.ParserError as e:
        print(f"[Upload Error - Parser Error] {e}")
        flash('CSV íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))
    except MemoryError as e:
        print(f"[Upload Error - Memory Error] {e}")
        flash('íŒŒì¼ì´ ë„ˆë¬´ ì»¤ì„œ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))
    except Exception as e:
        print(f"[Upload Error] {e}")
        flash(f'íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}', 'error')
        return redirect(url_for('index'))

@app.route('/filter', methods=['POST'])
def filter_data():
    # POST ë°ì´í„°ë¥¼ ì„¸ì…˜ì— ì €ì¥í•˜ê³  GETìœ¼ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ (PRG íŒ¨í„´)
    session['filter_params'] = {
        'address': request.form.get('address'),
        'radius': float(request.form.get('radius', 10)),
        'area_range': request.form.get('area_range', session.get('area_range', 'all')),
        'build_year': request.form.get('build_year', session.get('build_year', 'all')),
        'sort_col': request.form.get('sort_col'),
        'sort_order': request.form.get('sort_order', 'desc')
    }
    return redirect(url_for('show_filtered_results'))

@app.route('/results')
def show_filtered_results():
    # ì„¸ì…˜ì—ì„œ í•„í„° íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    filter_params = session.get('filter_params')
    if not filter_params:
        return redirect(url_for('index'))
    
    address = filter_params.get('address')
    radius_km = filter_params.get('radius', 10)
    radius_m = radius_km * 1000
    area_range = filter_params.get('area_range', 'all')
    sort_col = filter_params.get('sort_col')
    sort_order = filter_params.get('sort_order', 'desc')
    
    print(f"[DEBUG] í•„í„° íŒŒë¼ë¯¸í„° í™•ì¸:")
    print(f"  - address: '{address}'")
    print(f"  - radius_km: {radius_km}")
    print(f"  - area_range: {area_range}")
    print(f"  - sort_col: {sort_col}")
    print(f"  - sort_order: {sort_order}")
    print(f"  - session datafile: {session.get('datafile', 'NOT_FOUND')}")
    print(f"  - filter_params: {filter_params}")
    
    # í˜ì´ì§€ë„¤ì´ì…˜ íŒŒë¼ë¯¸í„°
    page = int(request.args.get('page', 1))
    per_page = int(request.args.get('per_page', 20))  # ê¸°ë³¸ 20ê°œì”©

    # ì „ìš©ë©´ì  êµ¬ê°„ ì„¸ì…˜ì— ì €ì¥
    session['area_range'] = area_range

    if not address:
        print(f"[ERROR] ì£¼ì†Œê°€ ë¹„ì–´ìˆìŒ: '{address}'")
        return render_template('map.html', error='ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.', data=[], columns=[], center_lat=None, center_lon=None, radius=radius_m)

    if 'datafile' not in session:
        print(f"[ERROR] ì„¸ì…˜ì— datafileì´ ì—†ìŒ - ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ê±°ë‚˜ ì„¸ì…˜ ë§Œë£Œ")
        print(f"[INFO] ìë™ìœ¼ë¡œ ê°€ì¥ ìµœê·¼ ë¶„ì„ íŒŒì¼ ì‚¬ìš© ì‹œë„")
        
        # ê°€ì¥ ìµœê·¼ ë¶„ì„ íŒŒì¼ ì°¾ê¸°
        import glob
        analysis_files = glob.glob('uploads/*_ë¶„ì„ì™„ë£Œ.csv')
        if analysis_files:
            latest_file = max(analysis_files, key=os.path.getmtime)
            session['datafile'] = os.path.basename(latest_file)
            print(f"[INFO] ìë™ ë³µêµ¬ëœ ì„¸ì…˜ íŒŒì¼: {session['datafile']}")
        else:
            center_lat, center_lon = get_latlon_from_address(address)
            if center_lat is None or center_lon is None:
                return render_template('map.html', error='ì…ë ¥í•˜ì‹  ì£¼ì†Œë¡œ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì£¼ì†Œë¥¼ ë” ì •í™•íˆ ì…ë ¥í•´ ì£¼ì„¸ìš”.', data=[], columns=[], center_lat=None, center_lon=None, radius=radius_m)
            return render_template('map.html', data=[], columns=[], message='ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.', center_lat=center_lat, center_lon=center_lon, radius=radius_m)

    try:
        temp_filename = session['datafile']
        # í•­ìƒ uploads í´ë”ì—ì„œë§Œ ì°¾ë„ë¡ ê²½ë¡œ ê³ ì •
        temp_path = os.path.join(app.config['UPLOAD_FOLDER'], os.path.basename(temp_filename))
        df = pd.read_csv(temp_path, encoding='utf-8-sig')
        columns = df.columns.tolist()

        print(f"[DEBUG] ì£¼ì†Œ ì¢Œí‘œ ë³€í™˜ ìš”ì²­: '{address}'")
        center_lat, center_lon = get_latlon_from_address(address)
        print(f"[DEBUG] ì¢Œí‘œ ë³€í™˜ ê²°ê³¼: lat={center_lat}, lon={center_lon}")
        
        if center_lat is None or center_lon is None:
            print(f"[ERROR] ì¢Œí‘œ ë³€í™˜ ì‹¤íŒ¨ - ì£¼ì†Œ: '{address}'")
            return render_template('map.html', error='ì…ë ¥í•˜ì‹  ì£¼ì†Œë¡œ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì£¼ì†Œë¥¼ ë” ì •í™•íˆ ì…ë ¥í•´ ì£¼ì„¸ìš”.', data=[], columns=columns, center_lat=None, center_lon=None, radius=radius_m)

        # ë²ˆì§€ ì»¬ëŸ¼ ì •ê·œí™”: ìˆ«ì+í•˜ì´í”ˆë§Œ ë‚¨ê¸°ê³  ë¬¸ìì—´ë¡œ ë³€í™˜
        if 'ë²ˆì§€' in df.columns:
            df['ë²ˆì§€'] = df['ë²ˆì§€'].astype(str).str.replace(r'[^0-9\-]', '', regex=True)

        # --- ì „ìš©ë©´ì  êµ¬ê°„ í•„í„°ë§ ---
        area_col = None
        for col in ['ì „ìš©ë©´ì (ã¡)', 'ì „ìš©ë©´ì (\u33A1)']:
            if col in df.columns:
                area_col = col
                break
        if area_col:
            if area_range == 'le60':
                df = df[df[area_col] <= 60]
            elif area_range == 'gt60le85':
                df = df[(df[area_col] > 60) & (df[area_col] <= 85)]
            elif area_range == 'gt85le102':
                df = df[(df[area_col] > 85) & (df[area_col] <= 102)]
            elif area_range == 'gt102le135':
                df = df[(df[area_col] > 102) & (df[area_col] <= 135)]
            elif area_range == 'gt135':
                df = df[df[area_col] > 135]
            # 'all'ì€ í•„í„°ë§ ì—†ìŒ

        # --- ê±´ì¶•ë…„ë„ í•„í„°ë§ ---
        build_year = filter_params.get('build_year', 'all')
        if build_year != 'all' and 'ê±´ì¶•ë…„ë„' in df.columns:
            current_year = datetime.now().year
            df['ê±´ì¶•ë…„ë„'] = pd.to_numeric(df['ê±´ì¶•ë…„ë„'], errors='coerce')
            df = df.dropna(subset=['ê±´ì¶•ë…„ë„'])
            
            if build_year == 'recent5':
                df = df[df['ê±´ì¶•ë…„ë„'] >= (current_year - 5)]
            elif build_year == 'recent10':
                df = df[df['ê±´ì¶•ë…„ë„'] >= (current_year - 10)]
            elif build_year == 'recent15':
                df = df[df['ê±´ì¶•ë…„ë„'] >= (current_year - 15)]
            elif build_year == 'over15':
                df = df[df['ê±´ì¶•ë…„ë„'] < (current_year - 15)]

        # Filter by distance
        df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
        df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
        df = df.dropna(subset=['ìœ„ë„', 'ê²½ë„'])
        
        from geopy.distance import geodesic
        if not df.empty:
            df['ì¤‘ì‹¬ì ê³¼ì˜ê±°ë¦¬'] = df.apply(lambda row: geodesic((center_lat, center_lon), (row['ìœ„ë„'], row['ê²½ë„'])).meters / 1000, axis=1)  # km ë‹¨ìœ„
        else:
            df['ì¤‘ì‹¬ì ê³¼ì˜ê±°ë¦¬'] = np.nan
            
        filtered_df = df[df['ì¤‘ì‹¬ì ê³¼ì˜ê±°ë¦¬'] <= radius_km].copy()

        # --- ì •ë ¬ ê¸°ëŠ¥ ì¶”ê°€ ---
        if sort_col and sort_col in filtered_df.columns:
            # ìˆ«ì/ë¬¸ì êµ¬ë¶„ ì—†ì´ ì •ë ¬
            filtered_df = filtered_df.sort_values(by=sort_col, ascending=(sort_order=='asc'), na_position='last')

        # í‰ê·  ê±°ë˜ê¸ˆì•¡ ê³„ì‚° (ì•ˆì „í•˜ê²Œ)
        avg_price = 0
        if not filtered_df.empty and 'ê±°ë˜ê¸ˆì•¡' in filtered_df.columns:
            price_series = pd.to_numeric(filtered_df['ê±°ë˜ê¸ˆì•¡'], errors='coerce')
            avg_price = price_series.mean() if not price_series.isna().all() else 0
        
        # --- í˜ì´ì§€ë„¤ì´ì…˜ ì ìš© ---
        total_count = len(filtered_df)
        total_pages = (total_count + per_page - 1) // per_page  # ì˜¬ë¦¼ ê³„ì‚°
        
        # í˜ì´ì§€ ë²”ìœ„ ê²€ì¦
        if page < 1:
            page = 1
        elif page > total_pages and total_pages > 0:
            page = total_pages
        
        # í˜„ì¬ í˜ì´ì§€ ë°ì´í„° ì¶”ì¶œ
        start_idx = (page - 1) * per_page
        end_idx = start_idx + per_page
        paginated_df = filtered_df.iloc[start_idx:end_idx]
        
        data_records = paginated_df.to_dict(orient='records')  # type: ignore
        # --- ìˆ«ì í¬ë§·íŒ…: ë²ˆì§€, ê±°ë˜ê¸ˆì•¡ ì œì™¸ ëª¨ë“  ìˆ«ìì— ì‰¼í‘œ ì¶”ê°€ ---
        def format_number(val):
            try:
                if val is None or val == '' or (isinstance(val, float) and pd.isna(val)):
                    return ''
                if isinstance(val, (int, float)):
                    return '{:,}'.format(int(val))
                if isinstance(val, str) and val.replace(',', '').replace('.', '', 1).isdigit():
                    return '{:,}'.format(int(float(val)))
                return val
            except Exception:
                return val
        for row in data_records:
            for col in columns:
                # ê¸ˆì•¡, ë³´ì¦ê¸ˆ, ì›”ì„¸ ë“± 'ê¸ˆì•¡'ì´ í¬í•¨ëœ ëª¨ë“  ìˆ«ì ì»¬ëŸ¼ì— ì‰¼í‘œ ì¶”ê°€
                if ('ê¸ˆì•¡' in col or 'ë³´ì¦ê¸ˆ' in col or 'ì›”ì„¸' in col) and col in row and (isinstance(row[col], (int, float)) or (isinstance(row[col], str) and str(row[col]).replace(',', '').replace('.', '', 1).isdigit())):
                    row[col] = format_number(row[col])
                elif col == 'ê³„ì•½ë…„ì›”' and col in row and row[col] is not None and row[col] != '':
                    try:
                        # ê³„ì•½ë…„ì›”ì€ ì •ìˆ˜ë¡œ ë³€í™˜ (ì†Œìˆ˜ì  ì œê±°)
                        row[col] = str(int(float(row[col])))
                    except Exception:
                        pass
                elif (col == 'ì „ìš©ë©´ì (ã¡)' or col == 'ì „ìš©ë©´ì (ã¡)') and col in row and row[col] is not None and row[col] != '':
                    try:
                        row[col] = f"{float(row[col]):.2f}"
                    except Exception:
                        pass
                elif col == 'ì „ìš©í‰' and col in row and row[col] is not None and row[col] != '':
                    try:
                        row[col] = f"{float(row[col]):.2f}"
                    except Exception:
                        pass
                elif col == 'ì¸µ' and col in row and row[col] is not None and row[col] != '':
                    try:
                        row[col] = str(int(float(row[col])))  # ì •ìˆ˜ë¡œ ë³€í™˜
                    except Exception:
                        pass
                elif col == 'ê±´ì¶•ë…„ë„' and col in row and row[col] is not None and row[col] != '':
                    try:
                        row[col] = str(int(float(row[col])))  # ì •ìˆ˜ë¡œ ë³€í™˜
                    except Exception:
                        pass
                elif col == 'ì „ìš©í‰ë‹¹' and col in row and row[col] is not None and row[col] != '':
                    try:
                        row[col] = f"{float(row[col]):,.2f}"  # ì‰¼í‘œì™€ ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬
                    except Exception:
                        pass
                elif col == 'ê³µê¸‰í‰ë‹¹' and col in row and row[col] is not None and row[col] != '':
                    try:
                        row[col] = f"{float(row[col]):,.2f}"  # ì‰¼í‘œì™€ ì†Œìˆ˜ì  ë‘˜ì§¸ìë¦¬
                    except Exception:
                        pass
        data_records = clean_for_json(data_records)
        
        # í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´ ê³„ì‚°
        pagination_info = {
            'page': page,
            'per_page': per_page,
            'total_count': total_count,
            'total_pages': total_pages,
            'has_prev': page > 1,
            'has_next': page < total_pages,
            'prev_page': page - 1 if page > 1 else None,
            'next_page': page + 1 if page < total_pages else None,
            'start_item': start_idx + 1 if total_count > 0 else 0,
            'end_item': min(end_idx, total_count),
            'page_range': list(range(max(1, page - 2), min(total_pages + 1, page + 3)))
        }
        
        # ì•ˆì „í•œ ë°ì´í„° ì¤€ë¹„
        safe_data = {
            'data': data_records or [],
            'columns': columns or [],
            'avg_price': float(avg_price) if avg_price and not pd.isna(avg_price) else 0,
            'count': total_count,
            'no_data': total_count == 0,
            'message': 'í•„í„° ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.' if total_count == 0 else '',
            'center_lat': float(center_lat) if center_lat else 37.5665,  # ì„œìš¸ì‹œì²­ ì¢Œí‘œ
            'center_lon': float(center_lon) if center_lon else 126.978,
            'radius': radius_m,
            'first_lat': float(data_records[0].get('ìœ„ë„', 0)) if data_records else None,
            'first_lon': float(data_records[0].get('ê²½ë„', 0)) if data_records else None,
            'pagination': pagination_info
        }
        
        return render_template('results.html', **safe_data)
    except Exception as e:
        print(f"[Filter Error] {e}")
        error_pagination = {
            'page': 1,
            'per_page': per_page,
            'total_count': 0,
            'total_pages': 0,
            'has_prev': False,
            'has_next': False,
            'prev_page': None,
            'next_page': None,
            'start_item': 0,
            'end_item': 0,
            'page_range': []
        }
        error_data = {
            'error': f'í•„í„°ë§ ì¤‘ ì˜¤ë¥˜: {e}',
            'data': [],
            'columns': [],
            'avg_price': 0,
            'count': 0,
            'no_data': True,
            'message': 'í•„í„°ë§ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.',
            'center_lat': 36.815,
            'center_lon': 127.1138,
            'radius': radius_m,
            'first_lat': None,
            'first_lon': None,
            'pagination': error_pagination
        }
        return render_template('results.html', **error_data)

@app.route('/download', methods=['GET'])
def download_csv():
    if 'datafile' not in session or 'filter_params' not in session:
        flash('ë‹¤ìš´ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ê±°ë‚˜ í•„í„° ì¡°ê±´ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.', 'error')
        return redirect(request.referrer or url_for('index'))

    temp_filename = session['datafile']
    temp_path = os.path.join(app.config['UPLOAD_FOLDER'], temp_filename)

    if not os.path.exists(temp_path):
        flash('ë¶„ì„ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'error')
        return redirect(url_for('index'))

    try:
        df = pd.read_csv(temp_path, encoding='utf-8-sig')
        
        # ì„¸ì…˜ì—ì„œ ëª¨ë“  í•„í„° íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
        filter_params = session.get('filter_params', {})
        address = filter_params.get('address')
        radius_km = filter_params.get('radius', 10.0)
        area_range = filter_params.get('area_range', 'all')
        build_year = filter_params.get('build_year', 'all')

        if not address:
            flash('ë‹¤ìš´ë¡œë“œë¥¼ ìœ„í•´ ì£¼ì†Œë¥¼ ë¨¼ì € ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.', 'error')
            return redirect(request.referrer or url_for('index'))

        # --- show_filtered_resultsì™€ ë™ì¼í•œ í•„í„°ë§ ë¡œì§ ì ìš© ---
        
        # 1. ì£¼ì†Œ -> ì¢Œí‘œ ë³€í™˜
        center_lat, center_lon = get_latlon_from_address(address)
        if center_lat is None or center_lon is None:
            flash('ì£¼ì†Œì˜ ì¢Œí‘œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.', 'error')
            return redirect(request.referrer or url_for('index'))

        # 2. ì „ìš©ë©´ì  í•„í„°ë§
        area_col = next((col for col in ['ì „ìš©ë©´ì (ã¡)', 'ì „ìš©ë©´ì (\u33A1)'] if col in df.columns), None)
        if area_col:
            df[area_col] = pd.to_numeric(df[area_col], errors='coerce')
            if area_range == 'le60':
                df = df[df[area_col] <= 60]
            elif area_range == 'gt60le85':
                df = df[(df[area_col] > 60) & (df[area_col] <= 85)]
            elif area_range == 'gt85le102':
                df = df[(df[area_col] > 85) & (df[area_col] <= 102)]
            elif area_range == 'gt102le135':
                df = df[(df[area_col] > 102) & (df[area_col] <= 135)]
            elif area_range == 'gt135':
                df = df[df[area_col] > 135]

        # 3. ê±´ì¶•ë…„ë„ í•„í„°ë§
        if build_year != 'all' and 'ê±´ì¶•ë…„ë„' in df.columns:
            current_year = datetime.now().year
            df['ê±´ì¶•ë…„ë„'] = pd.to_numeric(df['ê±´ì¶•ë…„ë„'], errors='coerce')
            df = df.dropna(subset=['ê±´ì¶•ë…„ë„'])
            
            if build_year == 'recent5':
                df = df[df['ê±´ì¶•ë…„ë„'] >= (current_year - 5)]
            elif build_year == 'recent10':
                df = df[df['ê±´ì¶•ë…„ë„'] >= (current_year - 10)]
            elif build_year == 'recent15':
                df = df[df['ê±´ì¶•ë…„ë„'] >= (current_year - 15)]
            elif build_year == 'over15':
                df = df[df['ê±´ì¶•ë…„ë„'] < (current_year - 15)]
        
        # 4. ê±°ë¦¬ í•„í„°ë§
        df['ìœ„ë„'] = pd.to_numeric(df['ìœ„ë„'], errors='coerce')
        df['ê²½ë„'] = pd.to_numeric(df['ê²½ë„'], errors='coerce')
        df = df.dropna(subset=['ìœ„ë„', 'ê²½ë„'])
        
        from geopy.distance import geodesic
        if not df.empty:
            df['ì¤‘ì‹¬ì ê³¼ì˜ê±°ë¦¬(km)'] = df.apply(
                lambda row: geodesic((center_lat, center_lon), (row['ìœ„ë„'], row['ê²½ë„'])).kilometers,
                axis=1
            )
            df = df[df['ì¤‘ì‹¬ì ê³¼ì˜ê±°ë¦¬(km)'] <= radius_km].copy()
        else:
            df['ì¤‘ì‹¬ì ê³¼ì˜ê±°ë¦¬(km)'] = np.nan

        # ë‹¤ìš´ë¡œë“œ íŒŒì¼ ìƒì„±
        output = io.BytesIO()
        df.to_csv(output, index=False, encoding='utf-8-sig')
        output.seek(0)
        
        download_name = f'filtered_data_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        return send_file(output, as_attachment=True, download_name=download_name, mimetype='text/csv')

    except Exception as e:
        print(f"[Download Error] {e}")
        flash(f'ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}', 'error')
        return redirect(request.referrer or url_for('index'))

@app.route('/fill_latlon', methods=['GET'])
def fill_latlon():
    log_lines = []
    # 1. ìœ„ë„/ê²½ë„ ì—†ëŠ” í–‰ ìë™ ì±„ìš°ê¸°
    rows = supabase.table('apt_master_info').select('*').is_('la', None).execute().data
    for row in rows:
        uid = row['uid']
        lat, lon = None, None
        tried = []
        # 1) ë„ë¡œëª…(rdnmadr)
        if row.get('rdnmadr'):
            tried.append(f"ë„ë¡œëª…: {row['rdnmadr']}")
            lat, lon = get_latlon_from_address(row['rdnmadr'])
        # 2) lnno_adres(ì‹œêµ°êµ¬+ë²ˆì§€)
        if (not lat or not lon) and row.get('lnno_adres'):
            tried.append(f"lnno_adres: {row['lnno_adres']}")
            lat, lon = get_latlon_from_address(row['lnno_adres'])
        # 3) ë‹¨ì§€ëª…(apt_nm)
        if (not lat or not lon) and row.get('apt_nm'):
            tried.append(f"ë‹¨ì§€ëª…: {row['apt_nm']}")
            lat, lon = get_latlon_from_address(row['apt_nm'])
        if lat and lon:
            supabase.table('apt_master_info').update({'la': lat, 'lo': lon}).eq('uid', uid).execute()
            log_lines.append(f"[ì¢Œí‘œì—…ë°ì´íŠ¸] uid={uid}, la={lat}, lo={lon} | ì‹œë„: {tried}")
        else:
            log_lines.append(f"[ì¢Œí‘œì‹¤íŒ¨] uid={uid} | ì‹œë„: {tried}")
        time.sleep(0.2)
    # 2. ë²ˆì§€ ë¹„ì •ìƒ í–‰ ë„ë¡œëª… ê¸°ë°˜ ìë™ ë³´ì •
    def is_abnormal_bunji(bunji):
        if bunji is None or bunji == '' or str(bunji).startswith('-'):
            return True
        if re.fullmatch(r'\d{5,}', str(bunji)):
            return True
        return False
    rows2 = supabase.table('apt_master_info').select('*').execute().data
    for row in rows2:
        bunji = row.get('lnno_adres') or row.get('ë²ˆì§€')
        if is_abnormal_bunji(bunji):
            road_addr = row.get('rdnmadr')
            new_bunji = None
            if road_addr:
                # ì¹´ì¹´ì˜¤ë§µ APIë¡œ ë„ë¡œëª… ì£¼ì†Œ â†’ ë²ˆì§€ ì¶”ì¶œ
                url = 'https://dapi.kakao.com/v2/local/search/address.json'
                headers = {'Authorization': f'KakaoAK {os.environ.get("KAKAO_REST_API_KEY")}' }
                params = {'query': road_addr}
                resp = requests.get(url, headers=headers, params=params)
                if resp.status_code == 200:
                    docs = resp.json().get('documents')
                    if docs:
                        addr = docs[0].get('address')
                        if addr:
                            main = addr.get('main_address_no', '')
                            sub = addr.get('sub_address_no', '')
                            new_bunji = f"{main}-{sub}" if sub else main
            if new_bunji:
                supabase.table('apt_master_info').update({'lnno_adres': new_bunji}).eq('uid', row['uid']).execute()
                log_lines.append(f"[ë²ˆì§€ìˆ˜ì •] uid={row['uid']} | {bunji} â†’ {new_bunji} (ë„ë¡œëª…: {road_addr})")
            else:
                log_lines.append(f"[ë²ˆì§€ì‹¤íŒ¨] uid={row['uid']} | ë„ë¡œëª…ìœ¼ë¡œ ë²ˆì§€ ì°¾ê¸° ì‹¤íŒ¨ (ë„ë¡œëª…: {road_addr})")
            time.sleep(0.2)
    # ë¡œê·¸ íŒŒì¼ ì €ì¥
    log_path = os.path.join('uploads', f"fill_latlon_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")
    with open(log_path, 'w', encoding='utf-8') as f:
        for line in log_lines:
            f.write(line + '\n')
    return '<br>'.join(log_lines) + f'<br><br>ë¡œê·¸ íŒŒì¼: {log_path}'

if __name__ == '__main__':
    # 8001ë²ˆ í¬íŠ¸ì—ì„œ ì‹¤í–‰
    app.run(debug=True, port=8004, host='0.0.0.0')